---
title: "Az 1993 és 2002 közötti magyar kórházi ágyszám- és betegforgalmi kimutatások digitalizációja"
author: Ferenci Tamás (https://www.medstat.hu/)<br>
date: "`r gsub('  ', ' ', format(Sys.time(), '%Y. %B %e.'))`"
output:
  github_document:
    toc: true
    df_print: "kable"
    pandoc_args: ["--lua-filter=pandoc-quotes.lua"]
lang: hu
---

## Összefoglaló

- 1993 óta minden évben megjelenik az ún. Kórházi ágyszám- és betegforgalmi kimutatás, mely a hazai kórházi rendszer jellemzőinek legátfogóbb, nyilvánosan elérhető adatbázisa.
- Egy [korábbi projektemben](https://github.com/ferenci-tamas/korhaz-agyszam-betegforgalom-halalozas) letöltöttem és gépi úton feldolgozhatóvá tettem a 2003 után kiadott kimutatásokat, melyek elérhetőek elektronikus formában a Nemzeti Egészségbiztosítási Alapkezelő honlapján.
- A 2003 előtti kimutatások azonban nincsenek fent ezen a honlapon, és, mint kiderült, máshol sem, ugyanis nem is léteznek elektronikus formában -- ezekből eleve is csak papíralapú változatot nyomtattak. Éppen ezért egy új projektet indítottam, melynek célja ezen könyvek digitalizálása, a bennük lévő adatok elektronikus formára konvertálása és nyilvános közzététele gépi feldolgozásra is alkalmas formátumban.
- A projekt célja kettős. Ezen adatok történelmünk egy szeletét dokumentálják; én úgy tekintem, hogy ez egyfajta örökségünk, amit fontos, hogy akár az érdeklődők, akár a jövő történészei, egyáltalán, a következő generációk számára megőrizzünk. Ennek biztonságosabb formáját jelenti, ha ezek az információk nem csak papíron, hanem elektronikusan is megvannak. Másrészt ha az adatokat gépi úton feldolgozható formában is elérhetővé tesszük, akkor a puszta megőrzésen túl azt is elősegjük, hogy olyan elemzések tudjanak elkészülni, melyek a jelenleginél egy évtizeddel visszább tudnak menni, ennyivel nagyobb időbeli átfogásban tudják vizsgálni a magyar kórházi rendszer alakulását.
- Az [Országos Egészségtudományi Szakkönyvtár](https://medinfo.aeek.hu/) rendkívüli segítőkészségről téve tanúbizonyságot vállalta a könyvek szkennelésének fáradságos munkáját. Ezt köszönöm a könyvtár valamennyi dolgozójának, név szerint külön is Balla Andrea könyvtárvezetőnek és Kovács Ildikó könyvtárosnak.
- A beszkennelt oldalakat némi grafikai előkészítés után multimodális nagy nyelvi modellel ismertettem fel, mely lényegében egy optikai karakterfelismerést hajtott végre, de a szokásos módszereknél sokkal hatékonyabban, jól megőrizve az adatok táblázatos formátumát is. E nélkül valószínűleg lehetetlen lett volna számomra ekkora mennyiségű információ gépi úton feldolgozható formátumban történő digitalizálása.
- A felismerés ugyan szinte hibátlan volt, de nem tökéletesen hibátlan, így gondot fordítottam az adatok alapos ellenőrzésére is; a véleményem szerint ez minden ilyen és ehhez hasonló projektnél fontos kérdés. Ennek részleteit és tanulságait is ismertetem itt.
- Ezen az oldalon megadom a teljes kódot is, mely a feldolgozást végezte.
- A munka folyamatosan zajlik, egyelőre a 2002-es év feldolgozása fejeződött be. Ez az oldal bemutatja a projekt hátterét és dokumentálja a haladást.

## Motiváció

1993 óta minden évben megjelenik az ún. Kórházi ágyszám- és betegforgalmi kimutatás, mely a magyar kórházi rendszer infrastruktúrájára és teljesítményére vonatkozó legrészletesebb, nyilvánosan elérhető adatforrás. A Kimutatás tartalmazza valamennyi magyar fekvőbeteg-ellátó intézmény ágyszámait (külön a működő és szünetelő ágyak számát), betegforgalmi adatait (felvett betegek számát, valamint lebontásukat további sorsuk szerint: meghalt, eltávozott, más osztályra áthelyezett), egynapos ellátási esetszámait, teljesített ápolási napjainak számát, az ápolás átlagos időtartamát, az ágykihasználást és a halálozási arányt. Nagyon fontos, hogy mindez nem csak a kórházra összesen érhető el, hanem szakmák szerint -- belgyógyászat, sebészet stb. -- lebontva is.

A fentiekből fakadóan a Kimutatás alapvető adatforrásunk, ha a magyar kórházi rendszer jellemzőiről, illetve azok időbeli alakulásáról objektív, megalapozott vizsgálatokat akarunk folytatni. Hogy alakult a kórházi ágyak száma az elmúlt évtizedekben? Hogy alakult ez szakmánként, melyiknél csökkent és melyiknél nőtt? Tényleg vannak nagyon kis forgalmú kórházak, illetve kórházi osztályok? Tényleg egyre több szüneteltett ágy van manapság? Sikerült növelni az egynapos ellátások arányát? Hogy alakult a halálozási arány? Ha az ilyen és ehhez hasonló kérdésekre tudunk válaszolni, az sokszor nem pusztán leíró jellegű megállapítás, hanem segíti a folyamatok megértését, a múltbeli egészségpolitikai döntések értékelését, a helyzetünk alaposabb átlátását. (Illusztrálva is a fenti lehetőséget, néhány kérdésről, melyeket én fontosnak éreztem, [készítettem](https://github.com/ferenci-tamas/egeszsegpolitika-korhaz) egy hosszú elemzést, számos vizualizációval, összehasonlítással, kiegészítve személyes egészségpolitikai véleményemmel.) Itt azonban nem pusztán elemzésekről van szó: jó esetben, tehát ha a döntések adatokra alapozva születnek, akkor ezek az információk az egészségügyi tervezési, irányítási munkát is segítik és így hozzájárulnak a jobb minőségű döntéshozatalhoz, ezen keresztül pedig az ország egészségi állapotának javításához.

Ezen elemzések elkészüléséhez azonban természetesen az is fontos, hogy a kimutatások adatai feldolgozható formában elérhetőek legyenek.

A 2003-as és az utáni kimutatások letölthetőek a Nemzeti Egészségbiztosítási Alapkezelő (NEAK) [honlapjáról](https://neak.gov.hu/felso_menu/szakmai_oldalak/publikus_forgalmi_adatok/gyogyito_megelozo_forgalmi_adat/fekvobeteg_szakellatas_stat/korhazi_agyszam) elektronikus formátumban (PDF, illetve DOC fájlként). A probléma az, hogy attól még, mert elektronikus, nem dolgozható fel gépi úton, még a DOC fájlok sem: hiába lehet ezek tartalmához hozzáférni, azok több száz oldalon keresztül, össze-vissza széttördelt táblázatokban találhatóak meg, arról nem beszélve, hogy egy dokumentumban csak egyetlen év adatai találhatóak meg, míg az elemzésekhez jellemzően az időbeli trendek is fontosak, vagyis össze kell(ene) kapcsolni több év adatait. Ezt a problémát egy [korábbi projektem](https://github.com/ferenci-tamas/korhaz-agyszam-betegforgalom-halalozas) keretében megoldottam: számítógéppel beolvastam a DOC fájlokat, azonosítottam és összekapcsoltam a táblázatokat, kiszedtem a tartalmukat, majd egyetlen, gépi úton feldolgozható táblázatba rendeztem. Ezt végrehajtottam minden évre, és a kapott táblázatokból létrehoztam egyetlen nagy, immár évet is tartalmazó adattáblát, melyet különböző, gépi úton feldolgozható formátumokban bárki számára nyilvánosan elérhetővé tettem, hogy ezzel is segítsem a jó minőségű elemzések megszületését.

A fenti munka után is nyitva maradt azonban a 2003 előtti kimutatások kérdése. Vajon hol lehet ezeket elérni? Gyors kereséssel kiderül, hogy könyvtárakban fellelhetőek könyvként kinyomtatott példányok ezekből, így az első gondolatom az volt, hogy akkor biztos, hogy ezek is megvannak elektronikusan is (elvégre valahonnan csak ki kellett nyomtatni, nem?), csak valamiért nem tették fel a NEAK honlapra. Sajnos azonban csalódnom kellett. A NEAK-tól azt a tájékoztatást kaptam (Elemzési és Informatikai Osztály, 2023. május 25.), hogy ezek soha nem készültek el elektronikus változatban. Egész pontosan, idézem őket: "a 2003 évet megelőző időszakra vonatkozóan az alapadatokból egy riportgenerátor segítségével egy nyomtatott példány készült ezen statisztikából, melyet a nyomda sokszorosított", tehát a "riportgenerátor kimenete nem egy fileba ment, hanem rögtön a nyomtatóra". Vagyis ilyen fájlok azért nem érhetőek el a honlapon, mert nem is léteznek és soha nem is léteztek.

Most akkor mi legyen? Vesződjünk ezek után egyáltalán ezekkel a régi kimutatásokkal? Ezek ugyan napjainak aktuális kérdéseinek megválaszolásához talán már kevésbé fontosak, de én azt gondolom, hogy igenis van jelentőségük. Ezek az adatok történelmünk egy részéről szólnak. Igen, történelmünknek csak egy kis szelete az egészségügy (de egy fontos szelete), és igen, annak is csak egy szelete a kórházi ellátórendszer (de egy fontos szelete), és persze az is igaz, hogy ezek az adatforrások még erről a szeletről is csak korlátozott információkat adnak -- de alapvető információkat. Ha már nem tudunk mindent megőrizni, akkor azt hiszem mondhatjuk, hogy ezek a legalapvetőbb számszerű információk, amiket amúgy is érdemes megőrizni az utókor számára a magyar kórházi rendszer alakulásáról. Én úgy tekintem, hogy ez egyfajta örökségünk, és fontos, hogy akár az érdeklődők, akár a jövő történészei, egyáltalán, a következő generációk számára megőrizzük.

Éppen ezért arra gondoltam, hogy jó lenne a 2003 előtti anyagokat is megkeresni és a tartalmukat digitalizálni, részint a hozzáférhetőség kedvéért -- hogy lehessen nagyon hosszú idősoros elemzéseket is végezni, ha ezek az adatok is feldolgozhatóak gépi úton -- részint, hogy még biztosabban megőrizzük az utókor számára. (Egy megjegyzés ehhez az utóbbihoz: egyáltalán nem gondolom, hogy a papíralapú változatra nincs szükség, mert az elektronikus az "jobb" -- szokták mondani, hogy a papír kockázatos, mert elázik, elég, megsárgul stb., de valójában az elektronikus formátumoknak is megvannak a [maguk bajai](https://en.wikipedia.org/wiki/Digital_dark_age), így a legbiztosabb, jövő-állósági értelemben, ha mindkettő megvan. Az elektronikus további előnye természetesen a gyorsabb kereshetőség és a feldolgozhatóság.)

Szóval mit tegyünk most?

## A megoldás módszere

A fentiekből fakadóan első lépésben mindenképp szükség van a kinyomtatott kimutatásokra, illetve azok beszkennelésére. Szerencsére az [Országos Egészségtudományi Szakkönyvtárban](https://medinfo.aeek.hu/) fellelhető [valamennyi](https://medinfokat.aeek.hu/eredmenyek?szemp1=0&kiegtipus_1=&szerzotipus_1=&kiemeltipus_1=&adat1=K%C3%B3rh%C3%A1zi%20%C3%A1gysz%C3%A1m-%20%C3%A9s%20betegforgalmi%20kimutat%C3%A1s&hmuv1=0&szemp2=0&kiegtipus_2=&szerzotipus_2=&kiemeltipus_2=&adat2=&hmuv2=0&szemp3=0&kiegtipus_3=&szerzotipus_3=&kiemeltipus_3=&adat3=&show=0&dokt=0&nyelv=0&rend1=0&csonk=0&annot=0&ocr=n&attach=0&csk=0&db=10&template=normal&showall=%C3%96sszes&form_id=kereses_form&oldal=1) kimutatás 1993-tól 2002-ig. Felvettem a kapcsolatot a könyvtárral, és nagyon gyorsan hatalmas segítséget kaptam tőlük: felajánlották, hogy nekiállnak, és beszkennelik ezeket a könyveket. E nélkül soha nem valósulhatott volna meg ez a projekt; hálásan köszönöm a könyvtárnak és valamennyi dolgozójának a segítséget! Szeretném külön is, név szerint köszönetemet kifejezni Balla Andrea könyvtárvezetőnek, aki az első pillanattól fogva támogatta a projektet, és Kovács Ildikó könyvtárosnak, aki a szkennelés fáradságos munkáját végezte.

Ez már megoldja a megőrzés problémáját, de nem oldja meg a feldolgozhatóságét. Éppen ezért úgy döntöttem, hogy továbbhaladok.

Az első gondolatom az volt, hogy OCR-rel felismertetem a beszkennelt példányokat, de ezzel nem jutottam sokra. Ugyan megpróbáltam (a [Tesseract](https://tesseract-ocr.github.io/) nyílt forráskódú OCR rendszert használva) a felismerést, de az eredmény gyakorlatilag használhatatlan lett. Még az egyedi számok felismerése sem sikerült túl jól, de a táblázat struktúra megőrzése gyakorlatilag reménytelen képet mutatott. Az igazság az, hogy e ponton már majdnem feladtam volna, amikor támadt egy igazán 2020-as évekbeli ötletem -- mi volna ha megpróbálnánk multimodális nagy nyelvi modellel? ("AI segítségével", ahogy ma mondani szokták...)

Az eredmény sokkoló(an jó) volt: már első próbálkozásra is nagyon jó -- az OCR-t többszörösen kenterbe verő -- megoldást szolgáltatott, némi finomhangolás után pedig szinte tökéleteset. Egy dolgot azonban ezzel együtt is fontosnak tartok kiemelni: hatalmas szerencsém volt az összegzősorok jelenlétével. (A kimutatásban, miután felsorolja egy kórház összes szakmáját, szerepel egy "összes osztály együtt" sor. Ez, pár oszloptól eltekintve, egyszerűen a felette lévő sorok összegét tartalmazza.) A dolgot a hibaellenőrzés miatt érzem kritikusnak: ez amúgy is fontos lenne, de egy ilyen modellnél, aminél mi sem tudhatjuk pontosan, hogy mi történik a háttérben, pláne. Az összegzősorok azonban lényegében megoldják ezt a problémát: bár nem volna rá szükség, de én ezeket is beolvastattam, pusztán azért, hogy utána leellenőrizzem, hogy a részletező sorok összege valóban kiadja-e az összesen-sort. Azért mondtam, hogy ez lényegében megoldja a problémát, mert annak a valószínűsége, hogy elromlik valami a részletező sorban *és* elromlik valami ugyanott az összegző sorban is *és* úgy romlik el mindkettő, hogy közben az összeg egyezése megmaradjon, marginális.

Innentől nem volt más feladat, mint a fenti ellenőrzésen fennakadt táblázatok kézi javítása (kevés ilyen volt), és utána már összeállíthatóvá vált az digitális, gépi úton feldolgozható táblázat is, ezzel teljeskörűen megvalósítva a célkitűzést.

A táblázatok szkennelése és az imént leírt feldolgozása folyamatosan zajlik; jelenleg 2002 van meg. Ahogy a továbbiak elkészülnek, folyamatosan töltöm ide fel az eredményeket.

## Tanulságok

Az eddig elvégzett munka alapján a következő tanulságokat fogalmaztam meg:

- AI nélkül teljesen reménytelen lett volna a feladat. A nagyságrend kedvéért: 2002 évben önmagában mintegy 20 ezer beolvasandó számérték volt, ha az összes táblát egyben tekintjük. Most képzelje el bárki, ha ezt -- 178 oldalnyi táblázat! -- kézzel kellett volna begépelni... És ez még csak egyetlen év; ilyenből van 10. Soha az életben nem lett volna meg; megbecsülni sem tudom, hogy hány munkaóra lenne kézzel begépelni, ráadásul egy embertelen monoton feladat. Az AI használatával 25 perc alatt megvolt az eredmény! 
- Még egyszer kiemelném, hogy rendkívül fontos volt, hogy megvoltak az összegző sorok. A helyzet ugyanis az, hogy AI nem volt hibátlan. *Szinte* hibátlan volt, de nem hibátlan. Megint csak a nagyságrendet mondom: 2002 év feldolgozása során kb. 30 számot kellett kézzel javítanom, mert -- az összegzősor jelenléte miatt lehetővé vált -- ellenőrzés során kibukott, hogy valami nem stimmel. Ha meggondoljuk, ez persze elképesztően jó (20 ezerből 30 hiba, ez 99,9%-os jóság), de mégis, csak volt benne 30 hibás érték! Ha nincs az összegzősor, akkor ezt jó eséllyel soha meg nem találom -- vagyis kiadtam volna a kezemből valamit, amiben van 30 hibás érték. (Zárójelben: az is fontos tanulság, hogy -- pont emiatt a ritkaság miatt -- ezen a szúrópróba-szerű ellenőrzés sem igen segített volna.) Nyilván itt most erősen függ a dolog céljától, hogy ez mekkora baj, ebben az esetben nem haltak volna meg emberek, mert 30 szám hibás, de engem azért zavart volna. Úgyhogy nagyon kellettek az összegzősorok, vagyis általában, a tanulság az volt számomra, hogy az ilyen AI-os dolgoknál mindig gondolni kell az ellenőrzésre. Egyébként kb. 4-5 órám ment el a kézi javításra; tehát nem mondom, hogy egy pillanat alatt megvolt, de össze se lehet hasonlítani, hogy mennyi munka lett volna AI nélkül.

## Technikai részletek

A felismeréshez a [Google Gemini](https://gemini.google/hu/about/?hl=hu) rendszert használtam, a 2002-es évhez a 2.5-pro változatot. Az egész feladatot az [R statisztikai környezet](https://ferenci-tamas.github.io/r-nyelv/) alatt oldottam meg, a [gemini.R](https://github.com/jhk0530/gemini.R) csomag használatával.

Az adatok kezeléséhez a [`data.table`](https://ferenci-tamas.github.io/r-nyelv/datatable.html) csomagot fogjuk használni:

```{r}
library(data.table)
```

Első lépésben a PDF-et oldalanként képfájllá alakítottam. (Erre jó eséllyel nem lenne igazából szükség, mert egyben is fel tudná dolgozni, de így kicsit jobban kézbentarthatónak éreztem a feladatot.) Kicsit ráadásul próbáltam javítani is a képeken: egyrészt fekete-fehérré alakítottam a képet az [Otsu-algoritmust](https://www.ipol.im/pub/art/2016/158/) használva (az eredeti szkennelt kép szürkeárnyalatos volt, de természetesen itt a szürkének nincs jelentősége, csak fekete és fehér lehet az oldal igazából, így reméltem, hogy ez az átalakítás csökkenti a zajt), másrészt a [magick](https://imagemagick.org/script/command-line-options.php#deskew) könyvtár megfelelő parancsával megpróbáltam automatikusan kiegyenesíteni a képet (némelyik picit ferde volt eredetileg), hátha ez is segíti a későbbi felismerést. A kód:

```{r, eval = FALSE}
img <- magick::image_read_pdf("./input/Kimutatas-2002.pdf")

for(i in seq_len(pdftools::pdf_info("Kimutatas-2002.pdf")$pages)) {
  print(i)
  magick::image_write(
    magick::image_deskew(image.Otsu::image_otsu(img[i])),
    paste0("./Kimutatas-2002-png/Kimutatas-2002-", i, ".png"))
}
```

Ezt követte az AI-os lépés. (A képek közül előtte kézzel kiszedtem a fejezetes címlapokat, hogy csak az maradjon meg köztük, amin tényleges táblázat van.) A következő prompt-ot használtam:

> The image contains a large table. Please extract the information from that in tabular format. Include all columns, even those consisting only of zeros, but do not include the header rows. Be sure to include all columns, even duplicated ones. The table always contains 18 columns. Make sure to extract all 18 columns. If the extracted data does not contain 18 columns, re-extract the table. The first column of the table contains numbers or missing values, the second column contains texts. Make sure to extract these columns too. There is a string in the upper left hand corner, add it to all rows of the table as the first column. Only use the first line. There is a string in the upper right hand corner, which always starts with the string "Intézetkód :", followed by four characters. Add those four characters (even the leading zero or zeros) to all rows of the table as the second column. The information extracted from the table should start in the third column. Provide the response in CSV format. Use ; as a column separator.

A felismerés egyetlen nehézsége, hogy lassan fut le egy kérés, de mivel ezek teljesen függetlenek egymástól, így beküldhetünk párhuzamosítva egyszerre többet:

```{r, eval = FALSE}
promptstring <- readLines("prompt.txt")

cl <- parallel::makeCluster(parallel::detectCores() - 1)
parallel::clusterExport(cl, "promptstring")

RawData <- parallel::parLapply(
  cl, seq_len(length(list.files("./Kimutatas-2002-png/"))), function(i)
    gemini.R::gemini_image(list.files(
      "./Kimutatas-2002-png/", full.names = TRUE)[i], promptstring,
      "2.5-pro", maxOutputTokens = 65536))

parallel::stopCluster(cl)
```

Azt tapasztaltam, hogy egy dolgot kell ellenőrizni: néha a lista pár eleme egyszerűen `NULL` maradt. De mivel úgy tűnik ez csak valamilyen egyszeri probléma volt, így egy sima újra-futtatás megoldja:

```{r, eval = FALSE}
for(i in which(sapply(RawData, is.null))) {
  print(i)
  RawData[[i]] <- gemini.R::gemini_image(list.files(
    "./Kimutatas-2002-png/", full.names = TRUE)[i], promptstring, "2.5-pro",
    maxOutputTokens = 65536)
}
```

Ezután jöhetett a visszakapott eredmény (egy lista, melynek minden eleme egy oldal) feldolgozása:

```{r, eval = FALSE}
RawData2 <- lapply(1:length(RawData), function(i) {
  res <- RawData[[i]]
  res <- gsub("```csv\n", "", res)
  res <- gsub("\n```", "", res)
  res <- cbind(fread(res, sep = ";", dec = ",", quote = "",
                     keepLeadingZeros = TRUE, header = FALSE),
               file = sapply(strsplit(sapply(strsplit(
                 list.files("./Kimutatas-2002-png/"), "-"), `[[`, 3), ".",
                 fixed = TRUE), `[[`, 1)[i])
  # if(i == 10) res <- setNames(cbind(res[, 1:4], res[, 5], res[,5:20]),
  #                             c(paste0("V", 1:20), "file"))
  res
})
```

(A kikommentezett sor azért kell, mert 2002-ben volt egy kép, aminél nem bírtam elérni, hogy egy oszlop ne legyen duplikálódva.)

Egy egyszerű ellenőrzési lehetőség, hogy megnézzük, minden táblának 21 oszlopa van-e. Ha nem, bizonyos esetekben elég egy újra-futtatás:

```{r, eval = FALSE}
for(i in which(sapply(RawData2, ncol) != 21)) {
  print(i)
  RawData[[i]] <- gemini.R::gemini_image(list.files(
    "./Kimutatas-2002-png/", full.names = TRUE)[i], promptstring, "2.5-pro",
    maxOutputTokens = 65536)
}
```

Ezután persze újra el kell végeznünk a beolvasást: 

```{r, eval = FALSE}
RawData2 <- lapply(1:length(RawData), function(i) {
  res <- RawData[[i]]
  res <- gsub("```csv\n", "", res)
  res <- gsub("\n```", "", res)
  res <- cbind(fread(res, sep = ";", dec = ",", quote = "",
                     keepLeadingZeros = TRUE, header = FALSE),
               file = sapply(strsplit(sapply(strsplit(
                 list.files("./Kimutatas-2002-png/"), "-"), `[[`, 3), ".",
                 fixed = TRUE), `[[`, 1)[i])
  # if(i == 10) res <- setNames(cbind(res[, 1:4], res[, 5], res[,5:20]),
  #                             c(paste0("V", 1:20), "file"))
  res
})
```

Végezetül elmentjük az eredményt:

```{r, eval = FALSE}
saveRDS(RawData2, "./rawdata/RawData2-2002.rds")
```

E ponton hadd szúrjak be egy általános megjegyzést. Az AI-os megközelítés egyik problémája, hogy nem determinisztikus: még ha pontosan ugyanazzal a prompt-tal futtatjuk újra, akkor sem biztos, hogy pontosan ugyanazt az eredményt kapjuk vissza. Emiatt tökéletesen reprodukálható nem lesz a kód, de a fenti kimentést azért is tettem, hogy *innentől* reprodukálható legyen minden, ami történik.

Töltsük be a fájlt, és végezzük el a fenti két ellenőrzést, hogy megerősítsük, hogy ezek valóban rendben vannak:

```{r}
RawData2 <- readRDS("./rawdata/RawData2-2002.rds")
which(sapply(RawData2, ncol) != 21)
which(sapply(RawData2, is.null))
```

Amint látható, az eredmények átmentek az ellenőrzéseken.

A további feldolgozáshoz fűzzük össze a listát egyetlen nagy adattáblává:

```{r}
RawData2 <- rbindlist(RawData2)
```

Pár oszlop nem numerikusra van állítva, de ez csak beállítás kérdése, az adattartalom rendben van, úgyhogy alakítsuk át numerikussá:

```{r}
RawData2$V9 <- as.numeric(RawData2$V9)
RawData2$V10 <- as.numeric(RawData2$V10)
RawData2$V18 <- as.numeric(RawData2$V18)
RawData2$V19 <- as.numeric(RawData2$V19)
RawData2$V20 <- as.numeric(RawData2$V20)
```

A következő ellenőrzési lépés annak vizsgálata, hogy melyek azok a kórházak, ahol nem szerepel "Aktív betegellátó osztályok összesen" sor. Ez nem feltétlenül probléma, előfoprdulhat, hogy egy kórházban csak krónikus ellátás van, de le kell ellenőrizni, hogy valóban csak ekkor fordul-e ilyen elő:

```{r}
stopline <- c("Aktív betegell. oszt. együtt",
              "Aktív betegeil. oszt. együtt",
              "Aktív betegell. öszt. együtt",
              "Aktív betgell. oszt. együtt",
              "Aktív betegek. oszt. együtt")
RawData2[V2 %in% RawData2[, .(sum(V4 %in% stopline)), .(V2)][V1==0]$V2, 1:4]
```

(Az összegző sor keresésénél tekintettel kell lenni arra, hogy többféleképp lehet rövidítve, illetve, hogy elgépelés vagy rossz felismerés is előfordulhat. A fenti ellenőrzés egyben azt is visszaigazolja, hogy a `stoplines` változóba valóban felvettük az összes lehetséges alakot.)

Amint látjuk, a dolog rendben van: ezek valóban olyan kórházak, ahol csak krónikus ellátás van. Az ilyeneket elhagyjuk, hiszen minket most az aktív ellátás adatai érdekelnek:

```{r}
RawData2 <- RawData2[!V2 %in% RawData2[, .(sum(V4 %in% stopline)),
                                       .(V2)][V1==0]$V2]
```

Ezek után kimenthetjük az adatok releváns részét, tehát az összegzősort és a felette lévő sorokat:

```{r}
fwrite(RawData2[, .SD[1:which(V4 %in% stopline)[1]], .(V2)],
       "./rawdata/RawData2-2002-original.csv",
       dec = ",", sep =";", bom = TRUE)
```

Ez után jöhet az adatok ellenőrzése: megnyitottam a `RawData2-2002-original.csv` fájlt, és kézzel javítottam benne a hibákat. De mik a hibák? A következő ellenőrzéseket tudjuk elvégezni.

Az első és legfontosabb, hogy megnézzük, hogy az összegzősorban lévő érték valóban a felette lévő értékek összege-e:

```{r}
RawData2[, as.list(sum(abs(colSums(
  .SD[1:(which(V4 %in% stopline)[1] - 1), 4:16]) -
    .SD[which(V4 %in% stopline)[1]][, 4:16]), na.rm = TRUE)), .(V2)][V1 != 0]
```

(Az utolsó három oszlopra ezt az ellenőrzést nem tudjuk elvégezni, hiszen azoknál az összegzősor nem összeget jelent.)

Gyorsítja a hibakeresést, ha csinálunk egy olyan kiíratást, melyben egy "gyanús" kórház sorai alá odarakjuk, hogy az egyes oszlopokban mekkora az összegzősor és a kézzel kiszámolt összeg eltérése. Például:

```{r}
RawData2[V2 == "0703", as.list(rbind(.SD, abs(
  colSums(.SD[1:(which(V4 %in% stopline)[1] - 1), 5:17]) -
    .SD[which(V4 %in% stopline)[1]][, 5:17]), fill = TRUE))]
```

Az eltérések között lehetnek valódi hibák, tehát amikor a felismerés egyszerűen elrontott valamit, és olyanok, amikor bár az összegek nem egyeznek, mégsem tényleges hiba van a háttérben. Ez utóbbi eseteket a következő pontban egyesével is összegyűjtöm, hogy dokumentálva legyen milyen alapon hagytam benne olyan adatokat a táblázatban, ahol nem stimmel az összegzés.

A másik dolog, amit meg kell nézni, a hiányzó adatok előfordulása, hogy hol vannak hiányzó adatok, illetve, hogy mi hiányzik:

```{r}
apply(RawData2, 2, function(x) sum(is.na(x)))
RawData2[is.na(V6)]
```

Ezek szintén potenciálisan javítandó hibák lehetnek, de itt is igaz, hogy nem mindegyik az (előfordulhat, hogy az adat ténylegesen hiányzik a kimutatás táblázatában is); ezeket ugyanúgy a következő pontban dokumentáltam.

Miután végeztem a fenti hibajavításokkal, a javított fájlt elmentettem `RawData2-2002-corrected.csv` néven. (Igen, tudom, hogy ez ilyen formában nem reprodukálható lépés, de egy `diff` a két fájl között úgyis kiadja, hogy miket módosítottam.)

Töltsük be ezt a fájlt:

```{r}
RawData2 <- fread("./rawdata/RawData2-2002-corrected.csv", keepLeadingZeros = TRUE)
```

Majd ellenőrizzük, hogy ebben már valóban nincs hiba:

```{r}
RawData2[, as.list(sum(abs(
  colSums(.SD[1:(which(V4 %in% stopline)[1] - 1), 4:16]) -
    .SD[which(V4 %in% stopline)[1]][, 4:16]), na.rm = TRUE)), .(V2)][V1 != 0]
apply(RawData2, 2, function(x) sum(is.na(x)))
RawData2[is.na(V18)]
RawData2[is.na(V19)]
```

Látjuk, hogy csak ott nem stimmel az összegzősor, ami a -- következő pontban dokumentált módon -- nem valódi probléma, és csak ott van adathiány, ahol -- következő pontban dokumentált módon -- tényleges adathiány van a táblázatban is.

Ezek után már rászűrhetünk csak a részletező sorokra, és kidobhatjuk a `file` oszlopot amire többé már nem lesz szükség (eddig is csak a képfájl kikeresését gyorsította):

```{r}
RawData2 <- RawData2[, .SD[1:(which(V4 %in% stopline)[1] - 1)], .(V2)]
RawData2$file <- NULL
```

Állítsunk be rendes -- természetesen a korábbi projektben használt, 2003 utáni adatokkal egyező! -- oszlopneveket:

```{r}
colnames(RawData2) <- c(
  "KorhazRovid", "Korhaz", "SzakmaKod", "SzakmaMegnev", "OsszesAgy",
  "MukodoIAgy", "MukodoIIAgy", "TartoSzuneteloAgy",
  "OsszesAtlagAgy", "MukodoAtlagAgy", "ElbocsatottBetegSzam",
  "EltavozottBetegSzam", "MasOsztalyBetegSzam",
  "MeghaltBetegSzam", "EgynaposEsetSzam",
  "TeljesithetoApolasiNapSzam","TeljesitettApolasiNapSzam",
  "ApolasAtlTartam", "Agykihasznalas", "Halalozas"
)
```

Nézzük meg hogyan sikerült a szakmák neveinek felismerése:

```{r}
as.data.table(table(RawData2$SzakmaKod, RawData2$SzakmaMegnev))[N != 0][order(V1)]
```

Egész jó a helyzet, mindössze két elnevezést kell javítani, illetve egységesíteni:

```{r}
RawData2[SzakmaKod == "1"]$SzakmaMegnev <- "Belgyógyászat"
RawData2[SzakmaKod == "5"]$SzakmaMegnev <- "Csecsemő- és gyermekgyógyászat"
```

Még egy ellenőrzési lehetőséget ad az, ha összehasonlítjuk a közölt, és a kézzel kiszámolható halálozási arányokat:

```{r}
plot(RawData2$MeghaltBetegSzam / RawData2$ElbocsatottBetegSzam * 100,
     RawData2$Halalozas)
abline(0,1)
cor(RawData2$MeghaltBetegSzam / RawData2$ElbocsatottBetegSzam * 100,
    RawData2$Halalozas, use = "complete.obs")
```

Mivel minden stimmel, mentsük ki az eredményeket:

```{r}
openxlsx2::write_xlsx(RawData2, "./output/RawData-2002.xlsx")
```

## Adatbeolvasási megállapítások

Amint a fenti leírásból is kiderült, azokban az esetekben, ahol az összegzősor nem-egyezése, illetve az adathiány mögött tényleges beolvasási hiba volt, kézzel javítottam a táblázatot. Előfordultak azonban olyan esetek is, amikor nem valódi hiba állt az eltérés, illetve az adathiány mögött. A következőkben a teljesség és transzparencia kedvéért ezeket dokumentálom, megadva a kórház azonosítóját, és annak magyarázatát, hogy miért nem igényelt javítást az eltérés.

### 2002

Összegzési eltérések:

- 0701: tényleg hibás az összeg (462 430 az összeg, 462 455 szerepel)
- 0702: potenciálisan csak kerekítési hiba
- 1309: potenciálisan csak kerekítési hiba
- 1401: potenciálisan csak kerekítési hiba
- 1402: potenciálisan csak kerekítési hiba
- 0140: potenciálisan csak kerekítési hiba
- 0152: igazából nincs hiba
- 9512: potenciálisan csak kerekítési hiba
- 0503: potenciálisan csak kerekítési hiba
- 0506: potenciálisan csak kerekítési hiba

Adathiányok:

- 9511: tényleges adathiány a 17-es szakmában az átlagos ápolási időtartamnál és az ágykihasználásnál
- 1801: tényleges adathiány a 17-es szakmában az átlagos ápolási időtartamnál és az ágykihasználásnál
- 1102: tényleges adathiány a 17-es szakmában az átlagos ápolási időtartamnál
- 1804: tényleges adathiány a 90-es szakmában az ágykihasználásnál